{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kit-v4399/229351-StatisticalLearning/blob/main/Copy_of_Lab02_Data_Preprocessing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X33DsAOeokmy"
      },
      "source": [
        "### Statistical Learning for Data Science 2 (229352)\n",
        "#### Instructor: Donlapark Ponnoprat\n",
        "\n",
        "#### [Course website](https://donlapark.pages.dev/229352/)\n",
        "\n",
        "## Lab #2"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder, OrdinalEncoder\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, roc_auc_score, roc_curve\n",
        "\n",
        "# For Fashion-MNIST\n",
        "from tensorflow.keras.datasets import fashion_mnist\n",
        "\n",
        "# For 20 Newsgroups\n",
        "from sklearn.datasets import fetch_20newsgroups\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "pd.set_option('display.max_columns', None)\n",
        "pd.set_option('display.width', 1000)"
      ],
      "metadata": {
        "id": "JOnoRSjo8dd5"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 1: Marketing Campaign Dataset - Manual Data Preprocessing & Logistic Regression"
      ],
      "metadata": {
        "id": "exuopfRD8mHt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load the Marketing Campaign Dataset ([Data Information](https://archive.ics.uci.edu/dataset/222/bank+marketing))\n",
        "\n",
        "The data is related with direct marketing campaigns of a Portuguese banking institution. The marketing campaigns were based on phone calls. Often, more than one contact to the same client was required, in order to access if the product (bank term deposit) would be (`'yes'`) or not (`'no'`) subscribed."
      ],
      "metadata": {
        "id": "FdWsJYcVBf1Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bank_url = 'https://raw.githubusercontent.com/donlap/ds352-labs/main/bank.csv'\n",
        "\n",
        "df = pd.read_csv(bank_url, sep=';', na_values=['unknown'])\n",
        "df = df.drop([\"emp.var.rate\", \"cons.price.idx\", \"cons.conf.idx\",\t\"euribor3m\", \"nr.employed\"], axis=1)\n",
        "print(\"Shape of the dataset:\", df.shape)\n",
        "df.head()"
      ],
      "metadata": {
        "id": "CJ9ujPUBBcTK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "outputId": "b14c68e2-ffd1-4598-f24a-0e3a903c9928"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of the dataset: (41188, 16)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   age        job  marital    education default housing loan    contact month day_of_week  duration  campaign  pdays  previous     poutcome   y\n",
              "0   56  housemaid  married     basic.4y      no      no   no  telephone   may         mon       261         1    999         0  nonexistent  no\n",
              "1   57   services  married  high.school     NaN      no   no  telephone   may         mon       149         1    999         0  nonexistent  no\n",
              "2   37   services  married  high.school      no     yes   no  telephone   may         mon       226         1    999         0  nonexistent  no\n",
              "3   40     admin.  married     basic.6y      no      no   no  telephone   may         mon       151         1    999         0  nonexistent  no\n",
              "4   56   services  married  high.school      no      no  yes  telephone   may         mon       307         1    999         0  nonexistent  no"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-649c4a62-eaa2-46dc-9b47-414fc29bc62a\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>job</th>\n",
              "      <th>marital</th>\n",
              "      <th>education</th>\n",
              "      <th>default</th>\n",
              "      <th>housing</th>\n",
              "      <th>loan</th>\n",
              "      <th>contact</th>\n",
              "      <th>month</th>\n",
              "      <th>day_of_week</th>\n",
              "      <th>duration</th>\n",
              "      <th>campaign</th>\n",
              "      <th>pdays</th>\n",
              "      <th>previous</th>\n",
              "      <th>poutcome</th>\n",
              "      <th>y</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>56</td>\n",
              "      <td>housemaid</td>\n",
              "      <td>married</td>\n",
              "      <td>basic.4y</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>telephone</td>\n",
              "      <td>may</td>\n",
              "      <td>mon</td>\n",
              "      <td>261</td>\n",
              "      <td>1</td>\n",
              "      <td>999</td>\n",
              "      <td>0</td>\n",
              "      <td>nonexistent</td>\n",
              "      <td>no</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>57</td>\n",
              "      <td>services</td>\n",
              "      <td>married</td>\n",
              "      <td>high.school</td>\n",
              "      <td>NaN</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>telephone</td>\n",
              "      <td>may</td>\n",
              "      <td>mon</td>\n",
              "      <td>149</td>\n",
              "      <td>1</td>\n",
              "      <td>999</td>\n",
              "      <td>0</td>\n",
              "      <td>nonexistent</td>\n",
              "      <td>no</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>37</td>\n",
              "      <td>services</td>\n",
              "      <td>married</td>\n",
              "      <td>high.school</td>\n",
              "      <td>no</td>\n",
              "      <td>yes</td>\n",
              "      <td>no</td>\n",
              "      <td>telephone</td>\n",
              "      <td>may</td>\n",
              "      <td>mon</td>\n",
              "      <td>226</td>\n",
              "      <td>1</td>\n",
              "      <td>999</td>\n",
              "      <td>0</td>\n",
              "      <td>nonexistent</td>\n",
              "      <td>no</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>40</td>\n",
              "      <td>admin.</td>\n",
              "      <td>married</td>\n",
              "      <td>basic.6y</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>telephone</td>\n",
              "      <td>may</td>\n",
              "      <td>mon</td>\n",
              "      <td>151</td>\n",
              "      <td>1</td>\n",
              "      <td>999</td>\n",
              "      <td>0</td>\n",
              "      <td>nonexistent</td>\n",
              "      <td>no</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>56</td>\n",
              "      <td>services</td>\n",
              "      <td>married</td>\n",
              "      <td>high.school</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>yes</td>\n",
              "      <td>telephone</td>\n",
              "      <td>may</td>\n",
              "      <td>mon</td>\n",
              "      <td>307</td>\n",
              "      <td>1</td>\n",
              "      <td>999</td>\n",
              "      <td>0</td>\n",
              "      <td>nonexistent</td>\n",
              "      <td>no</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-649c4a62-eaa2-46dc-9b47-414fc29bc62a')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-649c4a62-eaa2-46dc-9b47-414fc29bc62a button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-649c4a62-eaa2-46dc-9b47-414fc29bc62a');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-a1dbe886-1164-4ad8-abc4-d221dda4a0be\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-a1dbe886-1164-4ad8-abc4-d221dda4a0be')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-a1dbe886-1164-4ad8-abc4-d221dda4a0be button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 41188,\n  \"fields\": [\n    {\n      \"column\": \"age\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 10,\n        \"min\": 17,\n        \"max\": 98,\n        \"num_unique_values\": 78,\n        \"samples\": [\n          36,\n          56,\n          28\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"job\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 11,\n        \"samples\": [\n          \"retired\",\n          \"housemaid\",\n          \"entrepreneur\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"marital\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"married\",\n          \"single\",\n          \"divorced\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"education\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 7,\n        \"samples\": [\n          \"basic.4y\",\n          \"high.school\",\n          \"university.degree\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"default\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"yes\",\n          \"no\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"housing\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"yes\",\n          \"no\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"loan\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"yes\",\n          \"no\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"contact\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"cellular\",\n          \"telephone\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"month\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 10,\n        \"samples\": [\n          \"apr\",\n          \"jun\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"day_of_week\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"tue\",\n          \"fri\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"duration\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 259,\n        \"min\": 0,\n        \"max\": 4918,\n        \"num_unique_values\": 1544,\n        \"samples\": [\n          1805,\n          335\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"campaign\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2,\n        \"min\": 1,\n        \"max\": 56,\n        \"num_unique_values\": 42,\n        \"samples\": [\n          35,\n          19\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"pdays\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 186,\n        \"min\": 0,\n        \"max\": 999,\n        \"num_unique_values\": 27,\n        \"samples\": [\n          7,\n          12\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"previous\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 7,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          1,\n          5\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"poutcome\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"nonexistent\",\n          \"failure\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"y\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"yes\",\n          \"no\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Exploration"
      ],
      "metadata": {
        "id": "x4invEyyBRDI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"--- Missing Values Count ---\")\n",
        "print(df.isnull().sum())"
      ],
      "metadata": {
        "id": "u6wANpgzBQoK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"--- Unique Values for Categorical Columns ---\")\n",
        "for col in df.select_dtypes(include='object').columns:\n",
        "    print(f\"\\n'{col}' unique values:\")\n",
        "    print(df[col].value_counts(dropna=False)) # Include NaN counts"
      ],
      "metadata": {
        "id": "1ack00iLnuCy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Preprocessing"
      ],
      "metadata": {
        "id": "iCEtO_EWDTzC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Map target variable 'y' to 0 (no) and 1 (yes)\n",
        "df['y'] = # Write your code here\n",
        "\n",
        "\n",
        "# Drop 'duration' due to data leakage\n",
        "\n",
        "\n",
        "# Define features (X) and target (y)\n",
        "\n",
        "\n",
        "# Split the data BEFORE any transformations\n",
        "\n",
        "\n",
        "# Print data shape\n",
        "\n"
      ],
      "metadata": {
        "id": "W2J1Prc_BXe7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will apply `StandardScaler()`, `OrdinalEncoder()`, and `OneHotEncoder()` on a few selected columns."
      ],
      "metadata": {
        "id": "yM_gRkNjGR53"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1. Numerical Feature: `age` and `campaign` (Standard Scaling)**"
      ],
      "metadata": {
        "id": "r4sPr5qDGY65"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_cols_demo = ['age', 'campaign']\n",
        "\n",
        "scaler = StandardScaler()\n",
        "\n",
        "# Fit the scaler ONLY on the training data\n",
        "\n"
      ],
      "metadata": {
        "id": "52ibTHHFDxSv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2. Ordinal Feature: `education` (Ordinal Encoding with Imputation)**"
      ],
      "metadata": {
        "id": "8jQi5cJAGj_m"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- **Imputation**"
      ],
      "metadata": {
        "id": "2uyk1rA7K7_p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ord_col_demo = ['education']\n",
        "\n",
        "imputer_ord = SimpleImputer(strategy='most_frequent')\n",
        "\n",
        "## Write your code here\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "A8RbFYHLIhju"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- **Ordinal Encoding**"
      ],
      "metadata": {
        "id": "P9hDuDPyLGaA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "education_categories = [\n",
        "    'illiterate', 'basic.4y', 'basic.6y', 'basic.9y', 'high.school',\n",
        "    'professional.course', 'university.degree', 'masters', 'doctorate'\n",
        "]"
      ],
      "metadata": {
        "id": "n7DMoQ6AGf8h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ordinal_encoder = OrdinalEncoder(categories=[education_categories])\n",
        "\n",
        "## Write your code here\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "MjbM7wi8IfHn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3. Nominal Feature: `job` (One-Hot Encoding with Imputation)**"
      ],
      "metadata": {
        "id": "GarEnu8iK1lX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- **Imputation**"
      ],
      "metadata": {
        "id": "1eJSiEslLNi4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nom_col_demo = ['job']\n",
        "\n",
        "imputer_nom = SimpleImputer(strategy='most_frequent')\n",
        "imputer_nom.fit(X_train[nom_col_demo])\n",
        "\n",
        "X_train_imputed_nom_demo = imputer_nom.transform(X_train[nom_col_demo])\n",
        "X_test_imputed_nom_demo = imputer_nom.transform(X_test[nom_col_demo])"
      ],
      "metadata": {
        "id": "1OUbef1bJPUH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- **Nominal Encoding**"
      ],
      "metadata": {
        "id": "l7F_kim6TQ72"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "onehot_encoder = OneHotEncoder(handle_unknown='ignore', sparse_output=False)\n",
        "\n",
        "## Write your code here\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "6kMCGjksLyrf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Exercise 1: Apply All Preprocessing & Train Logistic Regression**\n",
        "\n",
        "Now, it's your turn to apply these preprocessing steps to *all* relevant columns and then train a Logistic Regression model.\n",
        "\n",
        "**Instructions:**\n",
        "\n",
        "1.  Look at the Variable Table in [this link](https://archive.ics.uci.edu/dataset/222/bank+marketing).\n",
        "2. Make lists for `numerical_features`, `ordinal_features`, and `nominal_features`.\n",
        "3. Preprocess the features. It is safer to make a copy of `X_train` using:\n",
        "   ```\n",
        "   X_train_copy = X_train.copy()\n",
        "   X_test_copy = X_test.copy()\n",
        "   ```\n",
        "   and preprocess `X_train_copy` instead.\n",
        "\n",
        "   **For nominal features, concat the one-hot encoded features using [`pd.concat(..., axis=1)`](https://pandas.pydata.org/docs/reference/api/pandas.concat.html) and drop the old nominal features from the dataframe.**\n",
        "4. Train Logistic Regression on the preprocessed `X_train_copy` and `y_train`.\n",
        "5. Evaluate the Model:\n",
        "    *   Make predictions on the preprocessed `X_test_copy`.\n",
        "    *   Print `classification_report` ([Documentation](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.classification_report.html)). What are the accuracy, average precision, average recall, and average f1-score?\n"
      ],
      "metadata": {
        "id": "CllpFvNBNYWI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- YOUR CODE FOR EXERCISE 1 STARTS HERE ---\n",
        "numerical_features = [\"age\", \"campaign\", \"duration\", \"previous\"]\n",
        "ordinal_features = [\"education\"]\n",
        "binary_features = ['default', \"housing\", \"loan\"]\n",
        "nominal_features = ['job', \"marital\", \"contact\"]\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X = df.drop('y', axis=1)\n",
        "y = df['y']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# copy dataframe\n",
        "X_train_copy = X_train.copy()\n",
        "X_test_copy  = X_test.copy()\n",
        "\n",
        "\n",
        "# เติมค่า missing (Imputer)\n",
        "\n",
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "# Numerical เติม median\n",
        "num_imputer = SimpleImputer(strategy='median')\n",
        "X_train_copy[numerical_features] = num_imputer.fit_transform(X_train_copy[numerical_features])\n",
        "X_test_copy[numerical_features]  = num_imputer.transform(X_test_copy[numerical_features])\n",
        "\n",
        "# Ordinal เติมค่าที่เจอบ่อยที่สุด\n",
        "ord_imputer = SimpleImputer(strategy='most_frequent')\n",
        "X_train_copy[ordinal_features] = ord_imputer.fit_transform(X_train_copy[ordinal_features])\n",
        "X_test_copy[ordinal_features]  = ord_imputer.transform(X_test_copy[ordinal_features])\n",
        "\n",
        "# Binary เติมค่าที่เจอบ่อยที่สุด (yes/no)\n",
        "bin_imputer = SimpleImputer(strategy='most_frequent')\n",
        "X_train_copy[binary_features] = bin_imputer.fit_transform(X_train_copy[binary_features])\n",
        "X_test_copy[binary_features]  = bin_imputer.transform(X_test_copy[binary_features])\n",
        "\n",
        "# Nominal เติมค่าที่เจอบ่อยที่สุด\n",
        "nom_imputer = SimpleImputer(strategy='most_frequent')\n",
        "X_train_copy[nominal_features] = nom_imputer.fit_transform(X_train_copy[nominal_features])\n",
        "X_test_copy[nominal_features]  = nom_imputer.transform(X_test_copy[nominal_features])\n",
        "\n",
        "\n",
        "# Preprocessing\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler, OrdinalEncoder\n",
        "import pandas as pd\n",
        "\n",
        "# Binary features map yes/no → 1/0\n",
        "for col in binary_features:\n",
        "    X_train_copy[col] = X_train_copy[col].map({'yes':1, 'no':0})\n",
        "    X_test_copy[col]  = X_test_copy[col].map({'yes':1, 'no':0})\n",
        "\n",
        "# Ordinal Encoding สำหรับ education\n",
        "education_categories = [\n",
        "    'illiterate', 'basic.4y', 'basic.6y', 'basic.9y', 'high.school',\n",
        "    'professional.course', 'university.degree', 'masters', 'doctorate'\n",
        "]\n",
        "# ทำการเลียงระดับการศึกษา\n",
        "ord_encoder = OrdinalEncoder(categories=[education_categories])\n",
        "X_train_copy[ordinal_features] = ord_encoder.fit_transform(X_train_copy[ordinal_features])\n",
        "X_test_copy[ordinal_features]  = ord_encoder.transform(X_test_copy[ordinal_features])\n",
        "\n",
        "# One-hot encode nominal features จะมี 1 แค่ตัวเดียว\n",
        "X_train_nominal = pd.get_dummies(X_train_copy[nominal_features], drop_first=True)\n",
        "X_test_nominal  = pd.get_dummies(X_test_copy[nominal_features], drop_first=True)\n",
        "\n",
        "# align columns ระหว่าง train/test ทำให้ columns ตรงกัน เหมือนทำให้ชุดที่ใส่ไซด์เดียวกัน\n",
        "X_train_nominal, X_test_nominal = X_train_nominal.align(X_test_nominal, join='outer', axis=1, fill_value=0)\n",
        "\n",
        "# concat กลับไปยัง dataframe หลัก ลบ columns ตัวหนังสือแล้วแทนด้วย colums One-hot\n",
        "X_train_copy = pd.concat([X_train_copy.drop(columns=nominal_features), X_train_nominal], axis=1)\n",
        "X_test_copy  = pd.concat([X_test_copy.drop(columns=nominal_features),  X_test_nominal],  axis=1)\n",
        "\n",
        "# Scale numerical features ทำให้ฟอร์มมันเกินคงที่\n",
        "scaler = StandardScaler()\n",
        "X_train_copy[numerical_features] = scaler.fit_transform(X_train_copy[numerical_features])\n",
        "X_test_copy[numerical_features]  = scaler.transform(X_test_copy[numerical_features])\n",
        "\n",
        "# One-hot encode additional categorical columns (month, day_of_week, poutcome)\n",
        "categorical_additional = ['month', 'day_of_week', 'poutcome']\n",
        "X_train_copy = pd.get_dummies(X_train_copy, columns=categorical_additional, drop_first=True)\n",
        "X_test_copy  = pd.get_dummies(X_test_copy,  columns=categorical_additional, drop_first=True)\n",
        "\n",
        "# align columns\n",
        "X_train_copy, X_test_copy = X_train_copy.align(X_test_copy, join='outer', axis=1, fill_value=0)\n",
        "\n",
        "\n",
        "# แปลง target y เป็น numeric\n",
        "\n",
        "y_train = y_train.map({'no':0, 'yes':1})\n",
        "y_test  = y_test.map({'no':0, 'yes':1})\n",
        "\n",
        "\n",
        "# Train Logistic Regression\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report, accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "model = LogisticRegression(max_iter=1000, random_state=42)\n",
        "model.fit(X_train_copy, y_train)\n",
        "\n",
        "# test set\n",
        "y_pred = model.predict(X_test_copy)\n",
        "\n",
        "\n",
        "#  Evaluate\n",
        "# classification report\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "# metric แยก\n",
        "accuracy  = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred)\n",
        "recall    = recall_score(y_test, y_pred)\n",
        "f1        = f1_score(y_test, y_pred)\n",
        "\n",
        "print(f'Accuracy : {accuracy:.4f}')\n",
        "print(f'Precision: {precision:.4f}')\n",
        "print(f'Recall   : {recall:.4f}')\n",
        "print(f'F1-score : {f1:.4f}')\n"
      ],
      "metadata": {
        "id": "xuI8hAlIRfDX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9f0d2b12-5e4f-484c-d004-04109e2f9c2c"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      0.98      0.95      7303\n",
            "           1       0.66      0.36      0.47       935\n",
            "\n",
            "    accuracy                           0.91      8238\n",
            "   macro avg       0.79      0.67      0.71      8238\n",
            "weighted avg       0.89      0.91      0.89      8238\n",
            "\n",
            "Accuracy : 0.9060\n",
            "Precision: 0.6557\n",
            "Recall   : 0.3626\n",
            "F1-score : 0.4669\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 2: Fashion-MNIST Dataset - Image Classification"
      ],
      "metadata": {
        "id": "m9qrm2DKRtgm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load Fashion-MNIST Dataset\n",
        "\n",
        "The Fashion-MNIST dataset consists of 28x28 grayscale images of fashion items."
      ],
      "metadata": {
        "id": "kc8SZBvcS8_I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "(fm_X_train, fm_y_train), (fm_X_test, fm_y_test) = fashion_mnist.load_data()\n",
        "\n",
        "print(f\"Fashion-MNIST Train data shape: {fm_X_train.shape}\")\n",
        "print(f\"Fashion-MNIST Train labels shape: {fm_y_train.shape}\")\n",
        "print(f\"Fashion-MNIST Test data shape: {fm_X_test.shape}\")\n",
        "print(f\"Fashion-MNIST Test labels shape: {fm_y_test.shape}\")"
      ],
      "metadata": {
        "id": "r0FQt8rlRgoI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"First image {fm_X_train[0]}\")\n",
        "print(f\"First label {fm_y_train[0]}\")"
      ],
      "metadata": {
        "id": "LXJ9EmcIVVrh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Visualize Fashion-MNIST Images\n",
        "\n",
        "Let's see what these images look like."
      ],
      "metadata": {
        "id": "WwkQOE79TV70"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fashion_mnist_class_names = [\n",
        "    'T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
        "    'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot'\n",
        "]\n",
        "\n",
        "# Visualize the images\n",
        "## Write your code here\n",
        "\n"
      ],
      "metadata": {
        "id": "-YUI6IzbTGYh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Exercise 2: Preprocessing Images (Flatten and Scale)**\n",
        "\n",
        "Images are 2D arrays (matrices of pixels) and pixel values are integers from 0-255. For Logistic Regression, we need:\n",
        "*  **Flattening:** Convert each 28x28 image into a 1D array of 784 features.\n",
        "*  **Scaling:** Normalize pixel values from [0, 255] to [0, 1].\n",
        "\n",
        "**Instructions:**\n",
        "\n",
        "1.   **Flatten:** Use the `.reshape()` method (see [documentation](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.reshape.html)). For `fm_X_train_binary` (shape `(num_samples, 28, 28)`), you want to reshape it to `(num_samples, 28*28)`.\n",
        "2.  **Scale:** Divide the flattened pixel values by 255.0 to get values between 0 and 1.\n",
        "3.   **Train Logistic Regression:**\n",
        "    *   Initialize `LogisticRegression(solver='saga')`. `saga` is a good solver when both number of samples and number of features are large.\n",
        "    *   Fit the model on your *processed* `fm_X_train_scaled` and `fm_y_train`.\n",
        "4.   **Make Predictions:** Use `predict()` to make predictions on the *processed* `fm_X_test_scaled`.\n",
        "5.   **Print Classification Report:** Print `classification_report` ([Documentation](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.classification_report.html)). What are the accuracy, average precision, average recall, and average f1-score?\n",
        "6.   **Visualize Misclassifications:**\n",
        "    *   Find the indices in `fm_X_test_binary` where your model made incorrect predictions (i.e., `fm_y_pred != fm_y_test`).\n",
        "    *   Select 5 of these misclassified images.\n",
        "    *   Plot these images (using `plt.imshow`). For each image, print its true label and its predicted label."
      ],
      "metadata": {
        "id": "cXvJB42xVrHu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- YOUR CODE FOR EXERCISE 2 STARTS HERE ---\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "P_Z7ooAgdLVf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 3: 20 Newsgroups Dataset - Text Classification"
      ],
      "metadata": {
        "id": "u7-q5FmnboVJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load 20 Newsgroups Dataset\n",
        "\n",
        "The 20 newsgroups dataset comprises around 18000 newsgroups posts on 20 topics."
      ],
      "metadata": {
        "id": "6TDncAyyb6mJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "news_train = fetch_20newsgroups(subset='train', shuffle=True, random_state=42)\n",
        "news_test = fetch_20newsgroups(subset='test', shuffle=True, random_state=42)\n",
        "\n",
        "X_train_news, y_train_news = news_train.data, news_train.target\n",
        "X_test_news, y_test_news = news_test.data, news_test.target\n",
        "\n",
        "print(f\"Number of training documents: {len(X_train_news)}\")\n",
        "print(f\"Number of test documents: {len(X_test_news)}\")\n",
        "print(f\"Categories: {news_train.target_names}\")"
      ],
      "metadata": {
        "id": "E91xZl5NbnpA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Explore Sample Document"
      ],
      "metadata": {
        "id": "tVCq09V2cfGj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the first document and its class\n",
        "## Write your code here\n",
        "\n"
      ],
      "metadata": {
        "id": "G37RNZGebFZG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Preprocessing: Text Vectorization Demonstration with `TfidfVectorizer`"
      ],
      "metadata": {
        "id": "1vXXUdp7chsX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "$$\n",
        "\\text{TF-IDF}(t, d, D) = \\text{TF}(t, d) \\times \\text{IDF}(t, D)\n",
        "$$\n",
        "\n",
        "Where:\n",
        "\n",
        "$$\n",
        "\\text{TF}(t, d) = \\frac{\\text{number of word }t\\text{ in } d}{\\text{number of words in } d} \\quad \\text{ and } \\quad\n",
        "\\text{IDF}(t, D) = \\log\\left(\\frac{\\text{total number of documents}}{\\text{number of documents that contain word }t}\\right).\n",
        "$$"
      ],
      "metadata": {
        "id": "rwaq1igbi-Hp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sample_sentences = [\n",
        "    \"This is the first document.\",\n",
        "    \"This document is the second document.\",\n",
        "    \"And this is the third one.\",\n",
        "    \"Is this the first document?\"\n",
        "]\n",
        "\n",
        "vectorizer = TfidfVectorizer(stop_words='english')\n",
        "\n",
        "# Fit and transform the sample sentences\n",
        "sample_vec_output_sparse = # Write your code here\n",
        "\n",
        "sample_vec_output_dense = sample_vec_output_sparse.toarray()\n",
        "\n",
        "print(vectorizer.vocabulary_)\n",
        "print(vectorizer.get_feature_names_out())\n",
        "print(sample_vec_output_dense)"
      ],
      "metadata": {
        "id": "8AaVd2D9ckKA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Exercise 3: Apply TF-IDF Vectorization to Full Dataset**\n",
        "\n",
        "Now, apply `TfidfVectorizer` to the actual training and testing datasets for the 20 Newsgroups classification task.\n",
        "\n",
        "**Instructions:**\n",
        "\n",
        "1.  **Initialize `TfidfVectorizer`:**\n",
        "    *   Initialize `TfidfVectorizer`. Use `stop_words='english'` to remove common words.\n",
        "2.  **Fit and Transform Training Data:**\n",
        "    *   Call `fit_transform()` on `X_train_news` to learn the vocabulary and transform the training text into TF-IDF features. Store the result in `X_train_vec`.\n",
        "3.  **Transform Test Data:**\n",
        "    *   Call `transform()` on `X_test_news` using the *already fitted* vectorizer. Store the result in `X_test_vec`. **Crucially, do not call `fit_transform()` on the test data!** This would cause data leakage.\n",
        "4.  **Initialize Logistic Regression:**\n",
        "    *   Initialize `LogisticRegression(solver='saga')`. `saga` is a good solver when both number of samples and number of features are large.\n",
        "5.  **Train the Model:**\n",
        "    *   Fit the model on your `X_train_vec` and `y_train_news`.\n",
        "6.  **Make Predictions:**\n",
        "    *   Make predictions using `predict()` on the `X_test_vec`.\n",
        "7.  **Evaluate the Model:**\n",
        "    *   Print `classification_report` ([Documentation](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.classification_report.html)). What are the accuracy, average precision, average recall, and average f1-score?"
      ],
      "metadata": {
        "id": "aCa_dcEDc-PQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- YOUR CODE FOR EXERCISE 3 STARTS HERE ---\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "B6g7y5yXrczq"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}